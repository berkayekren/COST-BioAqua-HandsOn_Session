{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a10e56dc",
   "metadata": {},
   "source": [
    "# üß† Machine Learning & Deep Learning for Microbiome and Multi-omics Data\n",
    "### Training Hands-on Session\n",
    "**Date:** _2025-10-21_  \n",
    "**Author:** _Berkay Ekren_  \n",
    "**Session:** Hands-On\n",
    "\n",
    "##### Required Packages\n",
    "1. Python >3.12\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f08996bc",
   "metadata": {},
   "source": [
    "## üïê Hands-on Session 1: Machine Learning for Microbiome and Multi-omics Case Studies\n",
    "### üìã Objectives:\n",
    "- Perform **classification** or **regression** using microbiome and omics datasets.\n",
    "- Identify **biomarkers** relevant to aquaculture species.\n",
    "\n",
    "### üîó Suggested Datasets:\n",
    "- Microbiome OTU/ASV tables\n",
    "- Metabolomics or transcriptomics profiles\n",
    "- Aquaculture phenotype or environmental metadata\n",
    "\n",
    "### üß∞ Tasks:\n",
    "1. Load and preprocess data\n",
    "2. Explore dataset (summary statistics, visualization)\n",
    "3. Early integration - Late integration methods\n",
    "4. Apply ML models (e.g., Random Forest, SVM, Gradient Boosting)\n",
    "5. Evaluate model performances\n",
    "6. Identify potential biomarkers (feature importance, SHAP, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b733473",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import data [1]\n",
    "microbiome_df = pd.read_csv(\"data/microbiome.csv\", sep=\"\\t\")\n",
    "metabolome_df = pd.read_csv(\"data/metabolome.csv\", sep=\"\\t\")\n",
    "\n",
    "# Uncomment the below 2 lines to see the first few rows of the dataframes to see the file structure\n",
    "#print(microbiome_df.head())\n",
    "#print(metabolome_df.head())\n",
    "\n",
    "# Check the distribution of the data with histograms\n",
    "plt.figure(figsize=(14, 5))\n",
    "sns.histplot(microbiome_df.iloc[:, 1:].values.flatten(), bins=50, color='blue', label='Microbiome', kde=True)\n",
    "sns.histplot(metabolome_df.iloc[:, 1:].values.flatten(), bins=50, color='orange', label='Metabolome', kde=True)\n",
    "plt.title('Distribution of Relative Abundance Values', fontsize=16)\n",
    "plt.xlabel('Abundance')\n",
    "plt.ylabel('Frequency')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "922c34a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.svm import SVC, SVR\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53a7f591",
   "metadata": {},
   "source": [
    "#### üß¨ Early integration in machine learning: Concatanate features before modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef4c386a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--- Strategy 1: Early Integration ---\")\n",
    "\n",
    "# 1. Set the first column as the index for each dataframe\n",
    "microbiome_features = microbiome_df.set_index(microbiome_df.columns[0])\n",
    "metabolome_features = metabolome_df.set_index(metabolome_df.columns[0])\n",
    "\n",
    "# 2. Transpose the dataframes so that rows are samples and columns are features\n",
    "X_microbiome = microbiome_features.T\n",
    "X_metabolome = metabolome_features.T\n",
    "\n",
    "# 3. Concatenate the dataframes horizontally (axis=1) to create a single feature matrix.\n",
    "# This aligns the data by sample ID (the index).\n",
    "early_integration_df = pd.concat([X_microbiome, X_metabolome], axis=1)\n",
    "\n",
    "print(\"Shape of Microbiome data (samples, features):\", X_microbiome.shape)\n",
    "print(\"Shape of Metabolome data (samples, features):\", X_metabolome.shape)\n",
    "print(\"Shape of combined data for Early Integration:\", early_integration_df.shape)\n",
    "\n",
    "print(\"\\n--- Early Integration DataFrame Head ---\")\n",
    "print(early_integration_df.head())\n",
    "\n",
    "# Split data for classification task\n",
    "X_train_early_c, X_test_early_c, y_train_c, y_test_c = train_test_split(\n",
    "    early_integration_df, y_classification, test_size=0.3, random_state=42\n",
    ")\n",
    "# Split data for regression task\n",
    "X_train_early_r, X_test_early_r, y_train_r, y_test_r = train_test_split(\n",
    "    X_early_integration, y_regression, test_size=0.3, random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "931c3057",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# 1. Early Integration: Concatenate features before modeling\n",
    "print(\"--- Strategy 1: Early Integration ---\")\n",
    "X_early_integration = pd.concat([X_microbiome, X_transcriptome], axis=1)\n",
    "\n",
    "\n",
    "\n",
    "# --- Models for Classification (Early Integration) ---\n",
    "print(\"\\nTraining Classification Models...\")\n",
    "classifiers = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000),\n",
    "    \"Random Forest\": RandomForestClassifier(random_state=42),\n",
    "    \"SVM\": SVC(probability=True, random_state=42),\n",
    "    \"XGBoost\": xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42),\n",
    "    \"LightGBM\": lgb.LGBMClassifier(random_state=42)\n",
    "}\n",
    "\n",
    "for name, model in classifiers.items():\n",
    "    print(f\"Fitting {name}...\")\n",
    "    # model.fit(X_train_early_c, y_train_c)\n",
    "    # score = model.score(X_test_early_c, y_test_c)\n",
    "    # print(f\"{name} Accuracy: {score:.4f}\")\n",
    "\n",
    "# --- Models for Regression (Early Integration) ---\n",
    "print(\"\\nTraining Regression Models...\")\n",
    "regressors = {\n",
    "    \"Random Forest\": RandomForestRegressor(random_state=42),\n",
    "    \"SVR\": SVR(),\n",
    "    \"XGBoost\": xgb.XGBRegressor(objective='reg:squarederror', random_state=42),\n",
    "    \"LightGBM\": lgb.LGBMRegressor(random_state=42)\n",
    "}\n",
    "\n",
    "for name, model in regressors.items():\n",
    "    print(f\"Fitting {name}...\")\n",
    "    # model.fit(X_train_early_r, y_train_r)\n",
    "    # score = model.score(X_test_early_r, y_test_r) # R^2 score\n",
    "    # print(f\"{name} R^2 Score: {score:.4f}\")\n",
    "\n",
    "\n",
    "# --- 2. Late Integration: Train models separately, then combine predictions (Stacking) ---\n",
    "print(\"\\n--- Strategy 2: Late Integration (Stacking) ---\")\n",
    "\n",
    "# Split individual datasets\n",
    "X_m_train, X_m_test, y_c_train, y_c_test = train_test_split(X_microbiome, y_classification, test_size=0.3, random_state=42)\n",
    "X_t_train, X_t_test, _, _ = train_test_split(X_transcriptome, y_classification, test_size=0.3, random_state=42)\n",
    "\n",
    "# --- Classification (Late Integration) ---\n",
    "# Step A: Train base models on each dataset\n",
    "base_model_m = RandomForestClassifier(random_state=42).fit(X_m_train, y_c_train)\n",
    "base_model_t = RandomForestClassifier(random_state=42).fit(X_t_train, y_c_train)\n",
    "\n",
    "# Step B: Get predictions from base models on the test set\n",
    "preds_m = base_model_m.predict_proba(X_m_test)[:, 1]\n",
    "preds_t = base_model_t.predict_proba(X_t_test)[:, 1]\n",
    "\n",
    "# Step C: Combine predictions to form a new feature set\n",
    "X_late_integration_test = np.c_[preds_m, preds_t]\n",
    "\n",
    "# To train the meta-model, you'd typically use cross-validated predictions on the training set.\n",
    "# For simplicity here, we'll just show the concept with a pre-trained meta-model.\n",
    "meta_model_c = LogisticRegression()\n",
    "# meta_model_c.fit(X_late_integration_train, y_c_train)\n",
    "# final_preds = meta_model_c.predict(X_late_integration_test)\n",
    "print(\"\\nLate integration concept for classification demonstrated.\")\n",
    "print(\"Meta-model would be trained on predictions from base models.\")\n",
    "\n",
    "# --- Regression (Late Integration) ---\n",
    "# The same principle applies. Base regressors are trained, and a final meta-regressor\n",
    "# (e.g., LinearRegression) is trained on their output predictions.\n",
    "print(\"\\nLate integration for regression follows the same stacking principle.\")\n",
    "\n",
    "# Note: The fitting and scoring lines are commented out.\n",
    "# You can uncomment them to run the models on the placeholder data.\n",
    "print(\"\\nSetup complete. Replace placeholder data and uncomment model.fit/score lines to run.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a13f28f6",
   "metadata": {},
   "source": [
    "## üïê Hands-on session 2: Deep Learning for Metagenomic & Multi-omics Data\n",
    "### üìã Objectives:\n",
    "- Build **deep learning** models to predict outcomes from multi-omics datasets.\n",
    "- Combine datasets (multi-view or multimodal learning).\n",
    "- Evaluate performance and interpretability.\n",
    "\n",
    "### üß¨ Suggested Frameworks:\n",
    "- TensorFlow / Keras\n",
    "- PyTorch / PyTorch Lightning\n",
    "\n",
    "### üß∞ Tasks:\n",
    "1. Prepare multi-omics datasets for modeling\n",
    "2. Define and train deep learning models\n",
    "3. Evaluate performance (accuracy, loss curves, confusion matrix)\n",
    "4. Interpret model predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e23a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üß¨ Example: Simple neural network with Keras\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# Example model\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(128, activation='relu', input_shape=(X_microbiome.shape[1],)),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "# model.fit(X_train, y_train, epochs=20, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91bf9eb6",
   "metadata": {},
   "source": [
    "## üïê Hands-on 3: Integrated Workflow ‚Äî From Data to Insights\n",
    "### üìã Objectives:\n",
    "- Build an **end-to-end workflow** from raw data ‚Üí preprocessing ‚Üí ML/DL models.\n",
    "- Combine microbiome, omics, and environmental data.\n",
    "- Derive interpretable **biological insights** relevant to aquaculture.\n",
    "\n",
    "### ‚öôÔ∏è Example Workflow Steps:\n",
    "1. Raw data QC and normalization\n",
    "2. Feature selection or dimensionality reduction\n",
    "3. Model training and validation\n",
    "4. Post-hoc interpretation and visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0956cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Integrated pipeline pseudocode\n",
    "# Step 1: Preprocess data\n",
    "# Step 2: Train model\n",
    "# Step 3: Evaluate results\n",
    "# Step 4: Visualize findings\n",
    "\n",
    "# Placeholder for pipeline code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad80c4ae",
   "metadata": {},
   "source": [
    "### üìö Suggested Reading & Resources\n",
    "- [QIIME 2 Machine Learning Plugin](https://docs.qiime2.org/)\n",
    "- [scikit-learn documentation](https://scikit-learn.org/stable/)\n",
    "- [TensorFlow tutorials](https://www.tensorflow.org/tutorials)\n",
    "- [PyTorch tutorials](https://pytorch.org/tutorials/)\n",
    "- Example dataset: [EBI Metagenomics](https://www.ebi.ac.uk/metagenomics/)\n",
    "\n",
    "**References**\n",
    "1. Mazzella, V., Dell‚ÄôAnno, A., Etxebarr√≠a, N., Gonz√°lez-Gaya, B., Nuzzo, G., Fontana, A., & N√∫√±ez-Pons, L. (2024). High microbiome and metabolome diversification in coexisting sponges with different bio-ecological traits. Communications Biology, 7(1), 422."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python_ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
